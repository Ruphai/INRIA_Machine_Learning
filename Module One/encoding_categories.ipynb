{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd09be38a6015254017d4edd2046b770be20849a1c5b230911009defc72922fbf9d",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Encoding Categorical Variables \n",
    "In this notebook, we will explore the two main techniques for handing categorical variables by encoding them. The two methods available for encoding categorical variables are Ordinal Encoding and One-Hot Encoding. In this notebook, we will explore their different use cases and how to work with them using the sci-kit Learn API. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will load in our datasets -- Adult Census -- containing both categorical and numerical features. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "adult_census = pd.read_csv(\"adult_census.csv\")\n",
    "\n",
    "# we will drop the duplicated columns -- education-num and the fnlwgt column. \n",
    "duplicated_columns = [\"education-num\", \"fnlwgt\"]\n",
    "adult_census = adult_census.drop(columns=duplicated_columns)\n",
    "\n",
    "#Identify the target class column and separate it from the input data. \n",
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "\n",
    "data = adult_census.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       age workclass   education       marital-status         occupation  \\\n",
       "23697   46   Private     HS-grad   Married-civ-spouse   Transport-moving   \n",
       "28261   31   Private   Assoc-voc        Never-married      Other-service   \n",
       "22019   23   Private     HS-grad   Married-civ-spouse       Craft-repair   \n",
       "\n",
       "      relationship    race      sex  capital-gain  capital-loss  \\\n",
       "23697      Husband   White     Male         15024             0   \n",
       "28261    Unmarried   White   Female             0             0   \n",
       "22019      Husband   White     Male             0             0   \n",
       "\n",
       "       hours-per-week  native-country   class  \n",
       "23697              44   United-States    >50K  \n",
       "28261              40   United-States   <=50K  \n",
       "22019              40   United-States   <=50K  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23697</th>\n      <td>46</td>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>Married-civ-spouse</td>\n      <td>Transport-moving</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>44</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>28261</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>Assoc-voc</td>\n      <td>Never-married</td>\n      <td>Other-service</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>22019</th>\n      <td>23</td>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "adult_census.sample(3)"
   ]
  },
  {
   "source": [
    "### Identifying Categorical variables. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " Divorced                  6633\n",
       " Married-AF-spouse           37\n",
       " Married-civ-spouse       22379\n",
       " Married-spouse-absent      628\n",
       " Never-married            16117\n",
       " Separated                 1530\n",
       " Widowed                   1518\n",
       "Name: marital-status, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data[\"marital-status\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " ?                               857\n",
       " Cambodia                         28\n",
       " Canada                          182\n",
       " China                           122\n",
       " Columbia                         85\n",
       " Cuba                            138\n",
       " Dominican-Republic              103\n",
       " Ecuador                          45\n",
       " El-Salvador                     155\n",
       " England                         127\n",
       " France                           38\n",
       " Germany                         206\n",
       " Greece                           49\n",
       " Guatemala                        88\n",
       " Haiti                            75\n",
       " Holand-Netherlands                1\n",
       " Honduras                         20\n",
       " Hong                             30\n",
       " Hungary                          19\n",
       " India                           151\n",
       " Iran                             59\n",
       " Ireland                          37\n",
       " Italy                           105\n",
       " Jamaica                         106\n",
       " Japan                            92\n",
       " Laos                             23\n",
       " Mexico                          951\n",
       " Nicaragua                        49\n",
       " Outlying-US(Guam-USVI-etc)       23\n",
       " Peru                             46\n",
       " Philippines                     295\n",
       " Poland                           87\n",
       " Portugal                         67\n",
       " Puerto-Rico                     184\n",
       " Scotland                         21\n",
       " South                           115\n",
       " Taiwan                           65\n",
       " Thailand                         30\n",
       " Trinadad&Tobago                  27\n",
       " United-States                 43832\n",
       " Vietnam                          86\n",
       " Yugoslavia                       23\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data[\"native-country\"].value_counts().sort_index()"
   ]
  },
  {
   "source": [
    "One way to easily recognize categorical columns among the datasets is to check the columns' data type. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "education         object\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "source": [
    "We will observe that columns containing string values have the data type objects stored in them. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature Selection based on data type\n",
    "Instead of manually selecting the categorical data types, we could use a scikit learn helper function called `make_column_selector` to select columns based on their data type. Let's see how this works."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'native-country']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.compose import make_column_selector as selector \n",
    "\n",
    "categorical_columns_selector = selector(dtype_include = object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "categorical_columns"
   ]
  },
  {
   "source": [
    "since we now have a list of column names that contain categorical data, we can filter out only the categorical data in our dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    workclass      education       marital-status          occupation  \\\n",
       "0     Private           11th        Never-married   Machine-op-inspct   \n",
       "1     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  native-country  \n",
       "0    Own-child   Black     Male   United-States  \n",
       "1      Husband   White     Male   United-States  \n",
       "2      Husband   White     Male   United-States  \n",
       "3      Husband   Black     Male   United-States  \n",
       "4    Own-child   White   Female   United-States  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Private</td>\n      <td>11th</td>\n      <td>Never-married</td>\n      <td>Machine-op-inspct</td>\n      <td>Own-child</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Local-gov</td>\n      <td>Assoc-acdm</td>\n      <td>Married-civ-spouse</td>\n      <td>Protective-serv</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Private</td>\n      <td>Some-college</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>Some-college</td>\n      <td>Never-married</td>\n      <td>?</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>United-States</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "data_categorical = data[categorical_columns]\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dataset is composed of 8 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset is composed of {data_categorical.shape[1]} features\")"
   ]
  },
  {
   "source": [
    "Now, that we have succesfully identified and filtered out the categorical features, we can now take a look at the different data encoding strategies for encoding categorical variables into numerical data that can be used by a machine learning algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Categorical Data Encoding strategies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Encoding ordinal categories\n",
    "The `OrdinalEncoder` will transform the data by encoding each category with a different number. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [11.],\n",
       "       [ 7.],\n",
       "       ...,\n",
       "       [11.],\n",
       "       [11.],\n",
       "       [11.]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "## A first look at how OrdinalEncoder works with a single column. \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "education_column = data_categorical[[\"education\"]]\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "education_encoded = encoder.fit_transform(education_column)\n",
    "education_encoded"
   ]
  },
  {
   "source": [
    "We could check the mapping between the categories and the numerical values that was assigned by the encoder. This is done by checking the fitted attribute `categories_`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th',\n",
       "        ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate',\n",
       "        ' HS-grad', ' Masters', ' Preschool', ' Prof-school',\n",
       "        ' Some-college'], dtype=object)]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 4.,  1.,  4.,  7.,  3.,  2.,  1., 39.],\n",
       "       [ 4., 11.,  2.,  5.,  0.,  4.,  1., 39.],\n",
       "       [ 2.,  7.,  2., 11.,  0.,  4.,  1., 39.],\n",
       "       [ 4., 15.,  2.,  7.,  0.,  2.,  1., 39.],\n",
       "       [ 0., 15.,  4.,  0.,  3.,  4.,  0., 39.]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# and then check the encoding applied on all categorical features\n",
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([' ?', ' Federal-gov', ' Local-gov', ' Never-worked', ' Private',\n",
       "        ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'],\n",
       "       dtype=object),\n",
       " array([' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th',\n",
       "        ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate',\n",
       "        ' HS-grad', ' Masters', ' Preschool', ' Prof-school',\n",
       "        ' Some-college'], dtype=object),\n",
       " array([' Divorced', ' Married-AF-spouse', ' Married-civ-spouse',\n",
       "        ' Married-spouse-absent', ' Never-married', ' Separated',\n",
       "        ' Widowed'], dtype=object),\n",
       " array([' ?', ' Adm-clerical', ' Armed-Forces', ' Craft-repair',\n",
       "        ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners',\n",
       "        ' Machine-op-inspct', ' Other-service', ' Priv-house-serv',\n",
       "        ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support',\n",
       "        ' Transport-moving'], dtype=object),\n",
       " array([' Husband', ' Not-in-family', ' Other-relative', ' Own-child',\n",
       "        ' Unmarried', ' Wife'], dtype=object),\n",
       " array([' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other',\n",
       "        ' White'], dtype=object),\n",
       " array([' Female', ' Male'], dtype=object),\n",
       " array([' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba',\n",
       "        ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England',\n",
       "        ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti',\n",
       "        ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India',\n",
       "        ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos',\n",
       "        ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru',\n",
       "        ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico',\n",
       "        ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago',\n",
       "        ' United-States', ' Vietnam', ' Yugoslavia'], dtype=object)]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dataset encoded has 8 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset encoded has {data_encoded.shape[1]} features\")"
   ]
  },
  {
   "source": [
    "It is important to note that the OrdinalEncoder uses a lexicographical strategy to map string category labels to integers. This categories are often arbitrary and meaningful and could even msilead downstream predictive models. A step ahead on this is the modification of the `categories` constructors provided by the OrdinalEncoder() method. \n",
    "\n",
    "If eventually, the categorical variable does not carry any meaningful order information then the `OrdinalEncoder()` might be misleading to downstream statistical and machine learning models. As such, an alternative encoding strategy would be the one-hot encoding strategy. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Encoding nominal categories (without assuming any order)\n",
    "`OneHotEncoder` is alternative encoder that prevents the  downstream models from making a false assumption about the ordering of categories. For any given feature, the OneHotEncoder will create as many new columns as there are possible categories. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here, we will start by encoding a single feature to showcase the idea behind how encoding works using the sci-kit learn API. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False) \n",
    "# Take a closer look at the concept of sparse matrices for compressing almost-empty matrices\n",
    "# https://scipy-lectures.org/advanced/scipy_sparse/introduction.html#why-sparse-matrices\n",
    "education_encoded = encoder.fit_transform(education_column)\n",
    "education_encoded"
   ]
  },
  {
   "source": [
    "Encoding a single features returns an Numpy array full of zeros and ones. In order to clearly understand this transformation, we can associate the feature names with the transformation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       education_ 10th  education_ 11th  education_ 12th  education_ 1st-4th  \\\n",
       "530                0.0              0.0              0.0                 0.0   \n",
       "34052              0.0              0.0              0.0                 0.0   \n",
       "43021              0.0              0.0              0.0                 0.0   \n",
       "40083              0.0              0.0              0.0                 0.0   \n",
       "43655              0.0              0.0              0.0                 0.0   \n",
       "22832              0.0              0.0              0.0                 0.0   \n",
       "41197              0.0              0.0              0.0                 0.0   \n",
       "28088              0.0              0.0              0.0                 0.0   \n",
       "33016              1.0              0.0              0.0                 0.0   \n",
       "44355              0.0              0.0              0.0                 0.0   \n",
       "\n",
       "       education_ 5th-6th  education_ 7th-8th  education_ 9th  \\\n",
       "530                   0.0                 0.0             0.0   \n",
       "34052                 0.0                 0.0             0.0   \n",
       "43021                 0.0                 0.0             0.0   \n",
       "40083                 0.0                 0.0             0.0   \n",
       "43655                 0.0                 0.0             0.0   \n",
       "22832                 0.0                 0.0             0.0   \n",
       "41197                 0.0                 0.0             0.0   \n",
       "28088                 0.0                 0.0             0.0   \n",
       "33016                 0.0                 0.0             0.0   \n",
       "44355                 0.0                 0.0             0.0   \n",
       "\n",
       "       education_ Assoc-acdm  education_ Assoc-voc  education_ Bachelors  \\\n",
       "530                      0.0                   0.0                   1.0   \n",
       "34052                    0.0                   0.0                   0.0   \n",
       "43021                    0.0                   0.0                   1.0   \n",
       "40083                    0.0                   0.0                   0.0   \n",
       "43655                    0.0                   0.0                   1.0   \n",
       "22832                    0.0                   0.0                   0.0   \n",
       "41197                    0.0                   1.0                   0.0   \n",
       "28088                    0.0                   0.0                   0.0   \n",
       "33016                    0.0                   0.0                   0.0   \n",
       "44355                    0.0                   0.0                   0.0   \n",
       "\n",
       "       education_ Doctorate  education_ HS-grad  education_ Masters  \\\n",
       "530                     0.0                 0.0                 0.0   \n",
       "34052                   0.0                 1.0                 0.0   \n",
       "43021                   0.0                 0.0                 0.0   \n",
       "40083                   0.0                 0.0                 0.0   \n",
       "43655                   0.0                 0.0                 0.0   \n",
       "22832                   0.0                 0.0                 0.0   \n",
       "41197                   0.0                 0.0                 0.0   \n",
       "28088                   0.0                 0.0                 0.0   \n",
       "33016                   0.0                 0.0                 0.0   \n",
       "44355                   0.0                 1.0                 0.0   \n",
       "\n",
       "       education_ Preschool  education_ Prof-school  education_ Some-college  \n",
       "530                     0.0                     0.0                      0.0  \n",
       "34052                   0.0                     0.0                      0.0  \n",
       "43021                   0.0                     0.0                      0.0  \n",
       "40083                   0.0                     0.0                      1.0  \n",
       "43655                   0.0                     0.0                      0.0  \n",
       "22832                   0.0                     0.0                      1.0  \n",
       "41197                   0.0                     0.0                      0.0  \n",
       "28088                   0.0                     0.0                      1.0  \n",
       "33016                   0.0                     0.0                      0.0  \n",
       "44355                   0.0                     0.0                      0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>education_ 10th</th>\n      <th>education_ 11th</th>\n      <th>education_ 12th</th>\n      <th>education_ 1st-4th</th>\n      <th>education_ 5th-6th</th>\n      <th>education_ 7th-8th</th>\n      <th>education_ 9th</th>\n      <th>education_ Assoc-acdm</th>\n      <th>education_ Assoc-voc</th>\n      <th>education_ Bachelors</th>\n      <th>education_ Doctorate</th>\n      <th>education_ HS-grad</th>\n      <th>education_ Masters</th>\n      <th>education_ Preschool</th>\n      <th>education_ Prof-school</th>\n      <th>education_ Some-college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>530</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>34052</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>43021</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40083</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>43655</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22832</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>41197</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28088</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>33016</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>44355</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "feature_names = encoder.get_feature_names(input_features=['education'])\n",
    "education_encoded = pd.DataFrame(education_encoded, columns=feature_names)\n",
    "education_encoded.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dataset is composed of 8 features\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    workclass      education       marital-status          occupation  \\\n",
       "0     Private           11th        Never-married   Machine-op-inspct   \n",
       "1     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  native-country  \n",
       "0    Own-child   Black     Male   United-States  \n",
       "1      Husband   White     Male   United-States  \n",
       "2      Husband   White     Male   United-States  \n",
       "3      Husband   Black     Male   United-States  \n",
       "4    Own-child   White   Female   United-States  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Private</td>\n      <td>11th</td>\n      <td>Never-married</td>\n      <td>Machine-op-inspct</td>\n      <td>Own-child</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Local-gov</td>\n      <td>Assoc-acdm</td>\n      <td>Married-civ-spouse</td>\n      <td>Protective-serv</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Private</td>\n      <td>Some-college</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>?</td>\n      <td>Some-college</td>\n      <td>Never-married</td>\n      <td>?</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>United-States</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "#We will now apply this encoding to the full dataset\n",
    "print(f\"The dataset is composed of {data_categorical.shape[1]} features\")\n",
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "data_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The encoded data has 102 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The encoded data has {data_encoded.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0           0.0                     0.0                   0.0   \n",
       "1           0.0                     0.0                   0.0   \n",
       "2           0.0                     0.0                   1.0   \n",
       "3           0.0                     0.0                   0.0   \n",
       "4           1.0                     0.0                   0.0   \n",
       "\n",
       "   workclass_ Never-worked  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                      0.0                 1.0                      0.0   \n",
       "1                      0.0                 1.0                      0.0   \n",
       "2                      0.0                 0.0                      0.0   \n",
       "3                      0.0                 1.0                      0.0   \n",
       "4                      0.0                 0.0                      0.0   \n",
       "\n",
       "   workclass_ Self-emp-not-inc  workclass_ State-gov  workclass_ Without-pay  \\\n",
       "0                          0.0                   0.0                     0.0   \n",
       "1                          0.0                   0.0                     0.0   \n",
       "2                          0.0                   0.0                     0.0   \n",
       "3                          0.0                   0.0                     0.0   \n",
       "4                          0.0                   0.0                     0.0   \n",
       "\n",
       "   education_ 10th  ...  native-country_ Portugal  \\\n",
       "0              0.0  ...                       0.0   \n",
       "1              0.0  ...                       0.0   \n",
       "2              0.0  ...                       0.0   \n",
       "3              0.0  ...                       0.0   \n",
       "4              0.0  ...                       0.0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    0.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     0.0                       0.0   \n",
       "4                    0.0                     0.0                       0.0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                              0.0                            1.0   \n",
       "1                              0.0                            1.0   \n",
       "2                              0.0                            1.0   \n",
       "3                              0.0                            1.0   \n",
       "4                              0.0                            1.0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                      0.0                         0.0  \n",
       "1                      0.0                         0.0  \n",
       "2                      0.0                         0.0  \n",
       "3                      0.0                         0.0  \n",
       "4                      0.0                         0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>workclass_ ?</th>\n      <th>workclass_ Federal-gov</th>\n      <th>workclass_ Local-gov</th>\n      <th>workclass_ Never-worked</th>\n      <th>workclass_ Private</th>\n      <th>workclass_ Self-emp-inc</th>\n      <th>workclass_ Self-emp-not-inc</th>\n      <th>workclass_ State-gov</th>\n      <th>workclass_ Without-pay</th>\n      <th>education_ 10th</th>\n      <th>...</th>\n      <th>native-country_ Portugal</th>\n      <th>native-country_ Puerto-Rico</th>\n      <th>native-country_ Scotland</th>\n      <th>native-country_ South</th>\n      <th>native-country_ Taiwan</th>\n      <th>native-country_ Thailand</th>\n      <th>native-country_ Trinadad&amp;Tobago</th>\n      <th>native-country_ United-States</th>\n      <th>native-country_ Vietnam</th>\n      <th>native-country_ Yugoslavia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 102 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "columns_encoded = encoder.get_feature_names(data_categorical.columns)\n",
    "pd.DataFrame(data_encoded, columns= columns_encoded).head()"
   ]
  },
  {
   "source": [
    "The number of features after the encoding is more than 10 times larger than in the original data because some variables such as `occupation` and `native-country` have many possible categories. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Choosing an encoding strategy\n",
    "Deciding on which encoding strategy to use will depend on the underlying model and the type of categories (ordinal or nominal). Linear models will be impacted by misordered categories while tree-based models will not be.\n",
    "In general, `OneHotEncoder` is the encoding strategy used when the downstream models are **linear models** while the `OrdinalEncoder` is used with **tree-based models**\n",
    "\n",
    "We can still use `OrdinalEncoder` with linear models, but you need to be sure that: \n",
    "- the orginal categories (before encoding) have an ordering, \n",
    "- the encoded categories follow the same ordering like the original categories. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evaluate our predictive pipeline\n",
    " At this point, it is now possible to integrate the encoder inside a machine learning pipeline like the one we used with numerical data. Here, we will train a linear classifier on the encoded data and compute the statistical performance of this ML pipeline using cross-validation. \n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " United-States                 43832\n",
       " Mexico                          951\n",
       " ?                               857\n",
       " Philippines                     295\n",
       " Germany                         206\n",
       " Puerto-Rico                     184\n",
       " Canada                          182\n",
       " El-Salvador                     155\n",
       " India                           151\n",
       " Cuba                            138\n",
       " England                         127\n",
       " China                           122\n",
       " South                           115\n",
       " Jamaica                         106\n",
       " Italy                           105\n",
       " Dominican-Republic              103\n",
       " Japan                            92\n",
       " Guatemala                        88\n",
       " Poland                           87\n",
       " Vietnam                          86\n",
       " Columbia                         85\n",
       " Haiti                            75\n",
       " Portugal                         67\n",
       " Taiwan                           65\n",
       " Iran                             59\n",
       " Greece                           49\n",
       " Nicaragua                        49\n",
       " Peru                             46\n",
       " Ecuador                          45\n",
       " France                           38\n",
       " Ireland                          37\n",
       " Thailand                         30\n",
       " Hong                             30\n",
       " Cambodia                         28\n",
       " Trinadad&Tobago                  27\n",
       " Outlying-US(Guam-USVI-etc)       23\n",
       " Yugoslavia                       23\n",
       " Laos                             23\n",
       " Scotland                         21\n",
       " Honduras                         20\n",
       " Hungary                          19\n",
       " Holand-Netherlands                1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# Before building the ML pipeline, let's have a look at some statistics on the native-country column. \n",
    "\n",
    "data['native-country'].value_counts()"
   ]
  },
  {
   "source": [
    "We noticed that the Holand-Netherlands category is occuring rarely. This will evnetually spell trouble during cross-validation: if the sample ends up in the test set during splitting and the classifier would not have seen the category during training and will not be able to encode it.\n",
    "In order to bypass this issue, two possible solutions are provided by sciki-learn: \n",
    "- list all the possible categories and provide it to the encoder via the keyword argument `categories`;\n",
    "- use the parameter `handle_unknown`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now, let's create our ML pipeline:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(OneHotEncoder(handle_unknown='ignore'), LogisticRegression(max_iter=500))"
   ]
  },
  {
   "source": [
    "Here, we need to increase the maximum number of iterations to obtain a fully converged LogisticRegression and silenece a CinvergenceWarning. Unlike numerical features, the one-hot encoded categorical features are all on the same scale (0 or 1), so they would not benefit from scaling. Which is why increasing max_iter is the right thing to do. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'fit_time': array([0.80627871, 0.82595897, 0.90604973, 0.94556165, 0.71154451]),\n",
       " 'score_time': array([0.02186966, 0.02361679, 0.02296591, 0.02792406, 0.0222857 ]),\n",
       " 'test_score': array([0.83222438, 0.83560242, 0.82872645, 0.83312858, 0.83466421])}"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# Check Model's Statistical Performance. \n",
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(model, data_categorical, target)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accuracy is: 0.833 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "print(f\"The accuracy is: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "source": [
    "The Accuracy shows us that the representration of the categorical variables is slightly more predictive of the revenue that the numerical variables we had used earlier. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}