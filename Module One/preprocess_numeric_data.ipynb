{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd09be38a6015254017d4edd2046b770be20849a1c5b230911009defc72922fbf9d",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preprocessing Numerical Features using sci-kit learn `StandardScaler` Transformer\n",
    "Although sci-kit learn provides a range of preprocessing algorithms for data transfromation before training the model, we are using the StandardScaler because we want to standardize the data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Background on Preprocessing Features\n",
    "A closer look at many Machine Learning algorithms will show us that they make assumptions about the distribution of features in a dataset. Hence, it is a good practise to normalize or scale the features to address these assumptions. \n",
    "\n",
    "## Why should we scale features?\n",
    "1. Models that rely on the distance between a pair of samples for instance K-nearest neighbor should be trained on normalized features to make each feature contribute equally to the distance computations. \n",
    "2. Many models such as logistic regression use a numerical solver () based on gradient descent to find their optimal parameters. These solvers converge faster when their features are scaled. \n",
    "\n",
    "In summary, whether or not a ML model requires feature scaling depends on the model family. Linear Models such as Logistic Regressions generally benefit greatly from feature scaling whereas other model families like Decision Trees might not necessarily require it but won't suffer any harm from it. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Data Preparation\n",
    "We first load the full datasets and remove the categorical features so we can focus on the numerical features in this notebook. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "adult_census = pd.read_csv(\"adult_census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
       "0   25     Private  226802           11th              7        Never-married   \n",
       "1   38     Private   89814        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private  160323   Some-college             10   Married-civ-spouse   \n",
       "4   18           ?  103497   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                   ?    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   class  \n",
       "0             0              40   United-States   <=50K  \n",
       "1             0              50   United-States   <=50K  \n",
       "2             0              40   United-States    >50K  \n",
       "3             0              40   United-States    >50K  \n",
       "4             0              30   United-States   <=50K  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>Private</td>\n      <td>226802</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Never-married</td>\n      <td>Machine-op-inspct</td>\n      <td>Own-child</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>89814</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>Local-gov</td>\n      <td>336951</td>\n      <td>Assoc-acdm</td>\n      <td>12</td>\n      <td>Married-civ-spouse</td>\n      <td>Protective-serv</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>Private</td>\n      <td>160323</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>7688</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>?</td>\n      <td>103497</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>?</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the target from the data features. \n",
    "target_name = 'class'\n",
    "\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    \"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "data_numeric = data[numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  capital-gain  capital-loss  hours-per-week\n",
       "0   25             0             0              40\n",
       "1   38             0             0              50\n",
       "2   28             0             0              40\n",
       "3   44          7688             0              40\n",
       "4   18             0             0              30"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>7688</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_numeric, target, random_state=42)"
   ]
  },
  {
   "source": [
    "### Model fiting and preprocessing\n",
    "Now, we will standardize our datasets and train a new logistic regression on the new version of the dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                age  capital-gain  capital-loss  hours-per-week\n",
       "count  36631.000000  36631.000000  36631.000000    36631.000000\n",
       "mean      38.642352   1087.077721     89.665311       40.431247\n",
       "std       13.725748   7522.692939    407.110175       12.423952\n",
       "min       17.000000      0.000000      0.000000        1.000000\n",
       "25%       28.000000      0.000000      0.000000       40.000000\n",
       "50%       37.000000      0.000000      0.000000       40.000000\n",
       "75%       48.000000      0.000000      0.000000       45.000000\n",
       "max       90.000000  99999.000000   4356.000000       99.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36631.000000</td>\n      <td>36631.000000</td>\n      <td>36631.000000</td>\n      <td>36631.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>38.642352</td>\n      <td>1087.077721</td>\n      <td>89.665311</td>\n      <td>40.431247</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.725748</td>\n      <td>7522.692939</td>\n      <td>407.110175</td>\n      <td>12.423952</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>37.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>48.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>90.000000</td>\n      <td>99999.000000</td>\n      <td>4356.000000</td>\n      <td>99.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display nice model diagram\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StandardScaler()"
      ],
      "text/html": "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"461348ff-7145-444e-b685-c9b987e069bf\" type=\"checkbox\" checked><label class=\"sk-toggleable__label\" for=\"461348ff-7145-444e-b685-c9b987e069bf\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#Here, we will use the sci-kit learn StandardScaler. This transformer shofts and scales each feature individually so that they all have a 0-mean and a unit standard deviation. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_train)\n",
    "\n",
    "# The fit method for transformers is similar to the fit method for predictors except that the former receives one argument while the later receives two arguments -- the data matrix and the target.\n",
    "\n",
    "# NOTE also that the algorithm need to compute the mean and standard deviation of each feature and store them as a numpy array. These statistics are the model states here. Note that the computation of mean and standard deviation as model states is specific to this algorithm, Other algorithms will compute different statistics and store them as model states in the same fashion as this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  38.64235211, 1087.07772106,   89.6653108 ,   40.43124676])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Let's inspect the computed means and standard deviation. \n",
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  13.72556083, 7522.59025606,  407.10461772,   12.42378265])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "source": [
    "You would have a sci-kit learn convention in the two code statements above. The convention is simply that if a feature is learned from the data, its name ends with an underscore _ as in mean_ and scaler_ for StandardScaler.\n",
    "\n",
    "Scaling data is performed per feature in the data matrix. That is, for each feature we substract its mean and divide by its standard deviation. Since we have the `fit` method, we can perform data transformation by calling the method `transform`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.17177061, -0.14450843,  5.71188483, -2.28845333],\n",
       "       [ 0.02605707, -0.14450843, -0.22025127, -0.27618374],\n",
       "       [-0.33822677, -0.14450843, -0.22025127,  0.77019645],\n",
       "       ...,\n",
       "       [-0.77536738, -0.14450843, -0.22025127, -0.03471139],\n",
       "       [ 0.53605445, -0.14450843, -0.22025127, -0.03471139],\n",
       "       [ 1.48319243, -0.14450843, -0.22025127, -2.69090725]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "data_train_scaled = scaler.transform(data_train)\n",
    "data_train_scaled\n",
    "# The transform method for transformers is similar to the predict method for predictors. Primarily, it uses a predefined function called a transformation function and uses the model states and the input data to output a transformed version of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.17177061, -0.14450843,  5.71188483, -2.28845333],\n",
       "       [ 0.02605707, -0.14450843, -0.22025127, -0.27618374],\n",
       "       [-0.33822677, -0.14450843, -0.22025127,  0.77019645],\n",
       "       ...,\n",
       "       [-0.77536738, -0.14450843, -0.22025127, -0.03471139],\n",
       "       [ 0.53605445, -0.14450843, -0.22025127, -0.03471139],\n",
       "       [ 1.48319243, -0.14450843, -0.22025127, -2.69090725]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# The method fit_transform is a shorthand method to call successively fit and then transform. \n",
    "data_train_scaled = scaler.fit_transform(data_train)\n",
    "data_train_scaled"
   ]
  },
  {
   "source": [
    "### Chaining Operations together with Scikit Learn Pipeline\n",
    "The scikit learn helper function make_pipeline will create a Pipeline, which takes as arguments the successive transformations to perform, followed by the classifier or regressor model. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ],
      "text/html": "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"37b5b865-e3f4-459d-89bb-eb8594b78270\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"37b5b865-e3f4-459d-89bb-eb8594b78270\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3e94c437-7090-486f-badf-f2e2819105a8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3e94c437-7090-486f-badf-f2e2819105a8\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8aeac4b4-8356-4919-9cb5-101dd9b2f869\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8aeac4b4-8356-4919-9cb5-101dd9b2f869\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'standardscaler': StandardScaler(),\n",
       " 'logisticregression': LogisticRegression()}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# We can check the name of each steps of our model. \n",
    "model.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' >50K', ' <=50K', ' <=50K'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "predicted_target = model.predict(data_test)\n",
    "predicted_target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accuracy using a Pipeline is 0.807 with a fitting time of 0.093 seconds in 12 iterations\n"
     ]
    }
   ],
   "source": [
    "## We can check the computational and statistical performance of our predictive pipeline\n",
    "model_name = model.__class__.__name__\n",
    "\n",
    "score = model.score(data_test, target_test)\n",
    "\n",
    "print(f\"The accuracy using a {model_name} is {score:.3f} \"\n",
    "      f\"with a fitting time of {elapsed_time:.3f} seconds \"\n",
    "      f\"in {model[-1].n_iter_[0]} iterations\")"
   ]
  },
  {
   "source": [
    "We could compare this predictive model with the predictive model we had developed earlier that did not scale features. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accuracy using a LogisticRegression is 0.807 with a fitting time of 0.153 seconds in 59 iterations\n"
     ]
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "score = model.score(data_test, target_test)\n",
    "print(f\"The accuracy using a {model_name} is {score:.3f} \"\n",
    "      f\"with a fitting time of {elapsed_time:.3f} seconds \"\n",
    "      f\"in {model.n_iter_[0]} iterations\")"
   ]
  },
  {
   "source": [
    "Our observation is that scaling the data before training the logistic regression model is more beneficial in terms of computational performance. Although, the statistical performance did not change for both models since they both converge, but a stark difference was noticed in the training time and the number of iterations. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model evaluation using cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}